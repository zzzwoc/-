{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files with specified classes removed to ai_data/train1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 输入文件夹路径\n",
    "input_folder = \"ai_data/train\"\n",
    "# 输出文件夹路径\n",
    "output_folder = \"ai_data/train1\"\n",
    "# 要删除的类别\n",
    "classes_to_remove = [0,2,3,4,5,7]  # 指定要删除的类别\n",
    "\n",
    "# 创建输出文件夹\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 遍历数据集并处理.txt文件\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            image_file = os.path.join(root, f\"{os.path.splitext(file)[0]}.jpg\")\n",
    "            with open(file_path, \"r\") as txt_file:\n",
    "                lines = txt_file.readlines()\n",
    "                updated_labels = []\n",
    "                for line in lines:\n",
    "                    label = int(line.split()[0])\n",
    "                    if label not in classes_to_remove:\n",
    "                        updated_labels.append(line.strip())\n",
    "                if updated_labels:\n",
    "                    # 创建新的标签文件并写入更新后的标签\n",
    "                    new_txt_file_path = os.path.join(output_folder, file)\n",
    "                    with open(new_txt_file_path, \"w\") as output_txt_file:\n",
    "                        output_txt_file.write('\\n'.join(updated_labels))\n",
    "                    # 复制对应的图像文件到新的文件夹\n",
    "                    if os.path.exists(image_file):\n",
    "                        shutil.copy(image_file, os.path.join(output_folder, f\"{os.path.basename(image_file)}\"))\n",
    "\n",
    "print(f\"Processed files with specified classes removed to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed files with specified classes removed to labels1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 输入文件夹路径\n",
    "input_folder = \"labels\"\n",
    "# 输出文件夹路径\n",
    "output_folder = \"labels1\"\n",
    "# 要删除的类别\n",
    "classes_to_remove = [8]  # 指定要删除的类别\n",
    "\n",
    "# 创建输出文件夹\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 遍历数据集并处理.txt文件\n",
    "for root, dirs, files in os.walk(input_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            image_file = os.path.join(root, f\"{os.path.splitext(file)[0]}.jpg\")\n",
    "            with open(file_path, \"r\") as txt_file:\n",
    "                lines = txt_file.readlines()\n",
    "                updated_labels = []\n",
    "                for line in lines:\n",
    "                    label = int(line.split()[0])\n",
    "                    if label not in classes_to_remove:\n",
    "                        updated_labels.append(line.strip())\n",
    "                if updated_labels:\n",
    "                    # 创建新的标签文件并写入更新后的标签\n",
    "                    new_txt_file_path = os.path.join(output_folder, file)\n",
    "                    with open(new_txt_file_path, \"w\") as output_txt_file:\n",
    "                        output_txt_file.write('\\n'.join(updated_labels))\n",
    "                    # 复制对应的图像文件到新的文件夹\n",
    "                    if os.path.exists(image_file):\n",
    "                        shutil.copy(image_file, os.path.join(output_folder, f\"{os.path.basename(image_file)}\"))\n",
    "\n",
    "print(f\"Processed files with specified classes removed to {output_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# 输入文件夹路径\n",
    "input_folder = \"3500\"\n",
    "# 输出训练集文件夹路径\n",
    "train_folder = \"07/train\"\n",
    "# 输出测试集文件夹路径\n",
    "test_folder = \"07/test\"\n",
    "# 拆分比例，例如 0.8 表示 80% 用于训练集，20% 用于测试集\n",
    "split_ratio = 0.8\n",
    "\n",
    "# 创建输出文件夹\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# 获取所有图像文件的文件名（假设图像文件和标签文件有相同的名称）\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith(\".jpg\")]\n",
    "\n",
    "# 随机打乱文件顺序\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# 确定拆分点\n",
    "split_point = int(len(image_files) * split_ratio)\n",
    "\n",
    "# 拆分文件并复制到相应的文件夹\n",
    "for i, file in enumerate(image_files):\n",
    "    if i < split_point:\n",
    "        shutil.copy(os.path.join(input_folder, file), os.path.join(train_folder, file))\n",
    "        label_file = os.path.splitext(file)[0] + \".txt\"\n",
    "        shutil.copy(os.path.join(input_folder, label_file), os.path.join(train_folder, label_file))\n",
    "    else:\n",
    "        shutil.copy(os.path.join(input_folder, file), os.path.join(test_folder, file))\n",
    "        label_file = os.path.splitext(file)[0] + \".txt\"\n",
    "        shutil.copy(os.path.join(input_folder, label_file), os.path.join(test_folder, label_file))\n",
    "\n",
    "print(\"Dataset split completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# 输入文件夹路径\n",
    "input_folder = \"ai_data/train__\"\n",
    "# 输出训练集文件夹路径\n",
    "train_folder = \"ai_data/train_/train\"\n",
    "# 输出测试集文件夹路径\n",
    "test_folder = \"ai_data/train_/test\"\n",
    "# 拆分比例，例如 0.8 表示 80% 用于训练集，20% 用于测试集\n",
    "split_ratio = 0.8\n",
    "\n",
    "# 创建输出文件夹\n",
    "os.makedirs(train_folder, exist_ok=True)\n",
    "os.makedirs(test_folder, exist_ok=True)\n",
    "\n",
    "# 获取所有图像文件的文件名（假设图像文件和标签文件有相同的名称）\n",
    "image_files = [f for f in os.listdir(input_folder) if f.endswith(\".jpg\")]\n",
    "\n",
    "# 随机打乱文件顺序\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# 确定拆分点\n",
    "split_point = int(len(image_files) * split_ratio)\n",
    "\n",
    "# 拆分文件并复制到相应的文件夹\n",
    "for i, file in enumerate(image_files):\n",
    "    if i < split_point:\n",
    "        shutil.copy(os.path.join(input_folder, file), os.path.join(train_folder, file))\n",
    "        label_file = os.path.splitext(file)[0] + \".txt\"\n",
    "        shutil.copy(os.path.join(input_folder, label_file), os.path.join(train_folder, label_file))\n",
    "    else:\n",
    "        shutil.copy(os.path.join(input_folder, file), os.path.join(test_folder, file))\n",
    "        label_file = os.path.splitext(file)[0] + \".txt\"\n",
    "        shutil.copy(os.path.join(input_folder, label_file), os.path.join(test_folder, label_file))\n",
    "\n",
    "print(\"Dataset split completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b8a5b0df6c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBboxParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from albumentations import Compose, BboxParams\n",
    "import albumentations as A\n",
    "\n",
    "# 定义数据增强函数\n",
    "class DataAugmenter:\n",
    "    def __init__(self):\n",
    "        self.transform = Compose([\n",
    "            A.Blur(p=0.15),             # 随机模糊\n",
    "            A.GaussianBlur(p=0.15),     # 高斯滤波器模糊\n",
    "            A.MedianBlur(p=0.15),       # 中值滤波器模糊输入图像\n",
    "            A.GaussNoise(p=0.15),        # 高斯噪声应用于输入图像\n",
    "            A.InvertImg(p=0.15),          # 通过从255中减去像素值来反转输入图像\n",
    "            A.ToGray(p=0.15),           # 将输入的 RGB 图像转换为灰度\n",
    "            A.CLAHE(p=0.15),            # 自适应直方图均衡\n",
    "            A.ChannelShuffle(p=0.15),   # 随机重新排列输入 RGB 图像的通道\n",
    "            A.ColorJitter(p=0.25),      # 随机改变图像的亮度、对比度和饱和度\n",
    "            A.FancyPCA(p=0.25),         # 使用FancyPCA增强RGB图像\n",
    "            A.Sharpen(p=0.15),          # 锐化输入图像并将结果与​​原始图像叠加\n",
    "            A.HueSaturationValue(p=0.15),           # 随机改变输入图像的色调、饱和度和值\n",
    "            A.RandomBrightnessContrast(p=0.15),     # 随机改变输入图像的亮度和对比度\n",
    "        ], bbox_params=BboxParams(format='yolo', label_fields=['class_labels']))\n",
    "\n",
    "    def augment(self, image, labels, p=1.0):\n",
    "        if self.transform and np.random.rand() < p:\n",
    "            transformed = self.transform(image=image, bboxes=labels[:, 1:], class_labels=labels[:, 0])\n",
    "            augmented_image, augmented_labels = transformed[\"image\"], np.array([[c, *b] for c, b in zip(transformed[\"class_labels\"], transformed[\"bboxes\"])])\n",
    "            return augmented_image, augmented_labels\n",
    "        else:\n",
    "            return image, labels\n",
    "\n",
    "# 输入文件夹和输出文件夹路径\n",
    "input_folder = 'ai_data/train'\n",
    "output_folder = 'ai_data/train_q'\n",
    "\n",
    "# 创建输出文件夹（如果不存在）\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 创建数据增强器\n",
    "augmenter = DataAugmenter()\n",
    "\n",
    "# 遍历输入文件夹中的图像和标签文件\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(input_folder, filename)\n",
    "        label_path = os.path.join(input_folder, filename.replace('.jpg', '.txt'))\n",
    "\n",
    "        # 读取图像\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # 读取标签\n",
    "        with open(label_path, 'r') as file:\n",
    "            lines = file.read().strip().split('\\n')\n",
    "\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            class_id, x, y, width, height = map(float, line.split())\n",
    "            labels.append([class_id, x, y, width, height])\n",
    "\n",
    "        # 进行数据增强\n",
    "        augmented_images = []\n",
    "        augmented_labels_list = []\n",
    "\n",
    "        for i in range(10):  # 生成10个增强样本\n",
    "            augmented_image, augmented_labels = augmenter.augment(image, np.array(labels))\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels_list.append(augmented_labels)\n",
    "\n",
    "        # 保存增强后的图像和标签\n",
    "        for i in range(len(augmented_images)):\n",
    "            output_image_path = os.path.join(output_folder, f\"{filename}_{i}.jpg\")\n",
    "            cv2.imwrite(output_image_path, augmented_images[i])\n",
    "\n",
    "            output_label_path = os.path.join(output_folder, f\"{filename}_{i}.txt\")\n",
    "            augmented_labels = augmented_labels_list[i]\n",
    "            with open(output_label_path, 'w') as file:\n",
    "                for label in augmented_labels:\n",
    "                    file.write(f'{label[0]} {label[1]} {label[2]} {label[3]} {label[4]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-bb66b368be67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCompose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBboxParams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "from albumentations import Compose, BboxParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-7c2496d7954d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 4: 3262 instances\n",
      "Class 3: 6053 instances\n",
      "Class 1: 6810 instances\n",
      "Class 0: 3761 instances\n",
      "Class 6: 1320 instances\n",
      "Class 5: 168 instances\n",
      "Class 2: 112 instances\n",
      "Class 7: 153 instances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "labels_dir = \"gr_ai_kuochong/train\"\n",
    "\n",
    "# 初始化一个字典来存储各类别的计数\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# 遍历标签文件\n",
    "for filename in os.listdir(labels_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        if (filename == 'classes.txt'):\n",
    "            continue\n",
    "        with open(os.path.join(labels_dir, filename), \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                # 标签文件通常是 \"<class_id> <x_center> <y_center> <width> <height>\" 的格式\n",
    "                # 你可能需要根据你的数据集的具体格式来解析\n",
    "                class_id = int(line.split()[0])\n",
    "                class_counts[class_id] += 1\n",
    "# 打印各类别的计数\n",
    "for class_id, count in class_counts.items():\n",
    "    print(f\"Class {class_id}: {count} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 1: 1720 instances\n",
      "Class 3: 1440 instances\n",
      "Class 0: 1018 instances\n",
      "Class 6: 313 instances\n",
      "Class 4: 834 instances\n",
      "Class 5: 48 instances\n",
      "Class 7: 34 instances\n",
      "Class 2: 39 instances\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "labels_dir = \"gr_ai_kuochong/test\"\n",
    "\n",
    "# 初始化一个字典来存储各类别的计数\n",
    "class_counts = defaultdict(int)\n",
    "\n",
    "# 遍历标签文件\n",
    "for filename in os.listdir(labels_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        if (filename == 'classes.txt'):\n",
    "            continue\n",
    "        with open(os.path.join(labels_dir, filename), \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                # 标签文件通常是 \"<class_id> <x_center> <y_center> <width> <height>\" 的格式\n",
    "                # 你可能需要根据你的数据集的具体格式来解析\n",
    "                class_id = int(line.split()[0])\n",
    "                class_counts[class_id] += 1\n",
    "# 打印各类别的计数\n",
    "for class_id, count in class_counts.items():\n",
    "    print(f\"Class {class_id}: {count} instances\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
